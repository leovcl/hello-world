{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xkcd/.virtualenvs/machl/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# chestii de DL\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calea catre mnist:  /Users/xkcd/.virtualenvs/machl/lib/python3.6/site-packages/keras/datasets/mnist.py\n"
     ]
    }
   ],
   "source": [
    "# calea catre fisierul mnist\n",
    "print(\"calea catre mnist: \",mnist.__file__)\n",
    "\n",
    "# ca sa avem toti aceleasi rezultate\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magic numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = 28*28\n",
    "nb_hidden_neurons_per_layer = 100\n",
    "nb_classes = 10\n",
    "optim = Adam()   # Stochastic Gradient Descent\n",
    "b_size = 128\n",
    "epoch = 20\n",
    "valid_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (60000, 28, 28)\n",
      "y_train.shape:  (60000,)\n",
      "x_test.shape:  (10000, 28, 28)\n",
      "y_test.shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \",x_train.shape)    # <- daca era vector len(x_train)\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "print(\"x_test.shape: \",x_test.shape)\n",
    "print(\"y_test.shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 154\n",
    "plt.imshow(x_train[index])\n",
    "print(\"label: \",y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In ce interval sunt datele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min pixelilor:  0\n",
      "max pixelilor:  255\n"
     ]
    }
   ],
   "source": [
    "print(\"min pixelilor: \",np.min(x_train))\n",
    "print(\"max pixelilor: \", np.max(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unroll the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (60000, 784)\n",
      "x_test.shape:  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],reshaped))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0],reshaped))\n",
    "\n",
    "print(\"x_train.shape: \",x_train.shape)\n",
    "print(\"x_test.shape: \",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure Float and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min pixelilor:  0.0\n",
      "max pixelilor:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# normalize\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(\"min pixelilor: \",np.min(x_train))\n",
    "print(\"max pixelilor: \", np.max(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  3\n"
     ]
    }
   ],
   "source": [
    "print(\"label: \",y_train[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test_onehot = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"label: \",y_train_onehot[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Neral Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(nb_hidden_neurons_per_layer, input_shape=(reshaped,)))\n",
    "model.add(Dense(nb_hidden_neurons_per_layer))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# get some info\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "  896/48000 [..............................] - ETA: 27s - loss: 1.8953 - acc: 0.3717 "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train_onehot, batch_size=b_size, epochs=epoch, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the score and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"score: \",score[0])\n",
    "print(\"accuracy: \",score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find examples where the algo failed"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_test => realitatea\n",
    "y_pred => nu il avem\n",
    "\n",
    "Comparam y_test cu y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a vector of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of how one prediction looks like "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because we have 10 digits, each prediction contains a vector of 10 values:\n",
    "these are interpreted as probabilities of having each of the digit in the image.\n",
    "We choose the index with the highest probability to be the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the first element in the testing data\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We construct a vector of failed predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, we must compare y_pred with y_test\n",
    "failed_pred = np.where((np.argmax(y_pred, axis=1) != np.argmax(y_test_onehot, axis=1)))\n",
    "print(\"failed_pred\")\n",
    "print(failed_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We choose one failed prediction and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the index is chosen from the list above (with failed predictions)\n",
    "index = 362\n",
    "\n",
    "x_test_prim = x_test[index]\n",
    "# remember that we reshaped the (28,28) tensor into a (784,) vector\n",
    "print(\"x_test_prim.shape: \",x_test_prim.shape)\n",
    "# in order to plot the image, we must convert from (784,) to (28,28)\n",
    "img_usable = np.expand_dims(x_test_prim, axis=0)\n",
    "img_to_show = np.reshape(x_test_prim, (28,28))\n",
    "plt.imshow(img_to_show)\n",
    "print(img_usable.shape)\n",
    "pred_prim = model.predict_classes(img_usable)\n",
    "print(\"The prediction: \",pred_prim)\n",
    "print(\"The reality: \",y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
